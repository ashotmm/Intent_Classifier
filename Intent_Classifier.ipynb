{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open file\n",
    "with open(\"C:/ML/training.data\") as f:\n",
    "    raw_data = f.readlines()\n",
    "raw_data = [x.strip('\\n') for x in raw_data]\n",
    "\n",
    "print(raw_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split every line by first occurence of space into (label, data)\n",
    "label_data = [x.split(' ', 1) for x in raw_data]\n",
    "len(label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_data[0])\n",
    "print(label_data[0][0])\n",
    "print(label_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get full labels from labels + data line\n",
    "label = []\n",
    "\n",
    "for i in range(len(label_data)):\n",
    "    label.append(label_data[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count total unique labels/classes\n",
    "unique_label = list(set(label))\n",
    "unique_label_count = len(unique_label)\n",
    "print(unique_label_count)\n",
    "print(unique_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get label separated into parts\n",
    "label_part = []\n",
    "label_part_0 = []\n",
    "label_part_1 = []\n",
    "\n",
    "for i in range(len(label)):\n",
    "    label_part.append(label[i].split(':'))\n",
    "    label_part_0.append(label_part[i][0])\n",
    "    label_part_1.append(label_part[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_part_0[0])\n",
    "print(label_part_1[0])\n",
    "print(label_part[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count unique label_part_0 and label_part_1 classes\n",
    "unique_label_0 = list(set(label_part_0))\n",
    "unique_label_count_0 = len(unique_label_0)\n",
    "print(unique_label_count_0)\n",
    "print(unique_label_0)\n",
    "\n",
    "unique_label_1 = list(set(label_part_1))\n",
    "unique_label_count_1 = len(unique_label_1)\n",
    "print(unique_label_count_1)\n",
    "print(unique_label_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate numerical labels instead of word labels by indexes in unique labels above\n",
    "label_part_num = []\n",
    "label_part_0_num = []\n",
    "label_part_1_num = []\n",
    "\n",
    "for i in range(len(label_part)):\n",
    "    for j in range(len(unique_label_0)):\n",
    "        for k in range(len(unique_label_1)):\n",
    "            if (label_part[i][0] == unique_label_0[j]) and  (label_part[i][1] == unique_label_1[k]):\n",
    "                label_part_num.append([j,k])\n",
    "                label_part_0_num.append(j)\n",
    "                label_part_1_num.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_part_0[0])\n",
    "print(label_part_1[0])\n",
    "print(label_part[0])\n",
    "\n",
    "print(label_part_0_num[0])\n",
    "print(label_part_1_num[0])\n",
    "print(label_part_num[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate unique numerical labels\n",
    "# this is the total space of classes, possibly useful in training/test\n",
    "# Note to self: during test, need to check if a numerical label was present in training set - if not\n",
    "# classifier has not seen this label during training, and cannot classify\n",
    "unique_label_part_num = []\n",
    "\n",
    "for x in label_part_num:\n",
    "    if x not in unique_label_part_num:\n",
    "        unique_label_part_num.append(x)\n",
    "\n",
    "unique_label_part_num_count = len(unique_label_part_num)\n",
    "\n",
    "print(unique_label_part_num_count)\n",
    "print(unique_label_part_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation: there are 50 different classes in total, as combination of 6 label_part_0 and 47 label_part_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get data from labels + data line\n",
    "data = []\n",
    "\n",
    "for i in range(len(label_data)):\n",
    "    data.append(label_data[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels and data are now stored in label_part_num, label_part_0_num, label_part_1_num, and data lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copy/rename data and labels to X and Y lists (for convention reasons)\n",
    "# Note that elements of X list are strings! - this is required for CountVectorizer input data format\n",
    "    \n",
    "X = data.copy()\n",
    "Y = label_part.copy()\n",
    "Y_num = label_part_num.copy()\n",
    "\n",
    "Y_str = []\n",
    "for i in range(len(Y_num)):\n",
    "    Y_str.append(str(Y_num[i][0]) + \",\" + str(Y_num[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check list lengths\n",
    "\n",
    "print(len(X))\n",
    "print(len(Y))\n",
    "print(len(Y_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data and labels are now stored in X, Y, Y_num, and Y_str lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide dataset into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split all datasets above into training/test sets with ratio 80/20%\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Note to self: scikit learn allows splitting multiple datasets with a single-line statement, but it is clearer to put things on separate lines\n",
    "train_set_X, test_set_X = train_test_split(X, test_size=0.2, random_state=42)\n",
    "train_set_Y, test_set_Y = train_test_split(Y, test_size=0.2, random_state=42)\n",
    "train_set_Y_num, test_set_Y_num = train_test_split(Y_num, test_size=0.2, random_state=42)\n",
    "train_set_Y_str, test_set_Y_str = train_test_split(Y_str, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_set_X))\n",
    "print(len(test_set_Y))\n",
    "print(str(len(train_set_X) + len(test_set_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick examples in test set, for which there are labels in the training set\n",
    "\n",
    "test_set_X_filt = []\n",
    "test_set_Y_str_filt = []\n",
    "\n",
    "for i in range(len(test_set_Y_str)):\n",
    "    if test_set_Y_str[i] in train_set_Y_str:\n",
    "        test_set_Y_str_filt.append(test_set_Y_str[i])\n",
    "        test_set_X_filt.append(test_set_X[i])\n",
    "\n",
    "len(test_set_Y_str_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = len(list(set(test_set_Y_str_filt)))\n",
    "print(unique) # number of labels in the filtered test set\n",
    "unique = len(list(set(test_set_Y_str)))\n",
    "print(unique) # number of labels in unfiltered/original test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since the length of the filtered test set is unchanged (3091), by chance all 50 of the labels in the test set are present in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize text with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note! CountVectorizer expects input data as sequence of strings, i.e. nparray will NOT work!\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(train_set_X)\n",
    "X_train_counts = count_vect.fit_transform(train_set_X)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test: look up index value for individual word (e.g.\"when\") \n",
    "count_vect.vocabulary_.get('when')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test: sparse matrix for X[0]\n",
    "print(X_train_counts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Naive Bayes classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, train_set_Y_str)\n",
    "\n",
    "# Accuracy on the training set\n",
    "import numpy as np\n",
    "predicted = clf.predict(X_train_tfidf)\n",
    "np.mean(predicted == train_set_Y_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build intent classifier pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "intent_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifier in one line, using pipeline\n",
    "intent_clf.fit(train_set_X, train_set_Y_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check prediction on the training set\n",
    "predicted = intent_clf.predict(train_set_X)\n",
    "np.mean(predicted == train_set_Y_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check prediction on the test set\n",
    "predicted = intent_clf.predict(test_set_X_filt)\n",
    "np.mean(predicted == test_set_Y_str_filt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note! n_iter parameter is renamed max_iter in sklearn v.0.19, additional parameter tol is introduced as well\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "intent_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, n_iter=5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check prediction on the training set\n",
    "intent_clf.fit(train_set_X, train_set_Y_str)\n",
    "predicted = intent_clf.predict(train_set_X)\n",
    "np.mean(predicted == train_set_Y_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check prediction on the test set\n",
    "predicted = intent_clf.predict(test_set_X_filt)\n",
    "np.mean(predicted == test_set_Y_str_filt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance analysis of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(test_set_Y_str_filt, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(test_set_Y_str_filt, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning using grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from time import time\n",
    "from pprint import pprint\n",
    "\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False), 'clf__alpha': (1e-2, 1e-3, 1e-4)}\n",
    "gs_clf = GridSearchCV(intent_clf, parameters, n_jobs=-1) # n_jobs = -1 uses all available cores\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in intent_clf.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "\n",
    "gs_clf.fit(train_set_X, train_set_Y_str)\n",
    "\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "# print(\"Best score: %0.3f\" % gs_clf.best_score_) # need to check the exact meaning of score\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = gs_clf.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "predicted = gs_clf.predict(train_set_X)\n",
    "np.mean(predicted == train_set_Y_str)\n",
    "\n",
    "print(\"Best accuracy: %0.3f\" % np.mean(predicted == train_set_Y_str))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The model with optimized parameter set can fit the training set (almost), perfectly, i.e. it is easy to overfit this set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(train_set_Y_str, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict with best parameters found by grid search above\n",
    "best_clf = gs_clf.best_estimator_\n",
    "predicted = best_clf.predict(test_set_X)\n",
    "np.mean(predicted == test_set_Y_str_filt)\n",
    "\n",
    "print(\"Accuracy on test set: %0.3f\" % np.mean(predicted == test_set_Y_str_filt)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set accuracy is 97.2%: the model will overfit the (small) test set, if parameters are optimized further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(test_set_Y_str_filt, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
